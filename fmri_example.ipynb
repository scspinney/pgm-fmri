{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fmri-example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMC+LLu8t496Xd2M4kZW2mG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scspinney/pgm-fmri/blob/main/fmri_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_kXdyg6_CsO"
      },
      "source": [
        "You might need to upload the files into the collab directory. The files used in this script are located inside the example dataset folder : \n",
        " \n",
        "\n",
        "*   sub-01/func/sub-01_task-stopsignal_run-01_bold.nii.gz\n",
        "*   sub-02/func/sub-02_task-stopsignal_run-01_bold.nii.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MabLCgikpHLx",
        "outputId": "f2106f93-ac85-4d7a-9ee7-607930d4c64a"
      },
      "source": [
        "!pip install nilearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/e7/59fcd3501f47b7a661a69e15ef417463fbc88dd334d9af2d9d6685710038/nilearn-0.7.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.18.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.1.4)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2->nilearn) (2020.11.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->nilearn) (1.15.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF3N4lXjmVyS"
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "from nilearn.image import index_img, smooth_img"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6pzNKdnnBG8"
      },
      "source": [
        "The datasets we will be using will be a set of nifti files, so we need a library which can read an manipulate those files into matrices. Nilearn is standard for python, and it has the tools we need to handle this type of data (see example dataset in README). We can build a list of 4D files, then read them one-by-one and extract the slices of interest. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA6-8pRsnKGQ"
      },
      "source": [
        "sub1_path = '/sub-01_task-stopsignal_run-01_bold.nii.gz'\n",
        "sub2_path = '/sub-02_task-stopsignal_run-01_bold.nii.gz'\n",
        "#sub1_path = '~/Downloads/open-neuro/sub-01/func/sub-01_task-stopsignal_run-01_bold.nii.gz'\n",
        "#sub2_path = '~/Downloads/open-neuro/sub-02/func/sub-02_task-stopsignal_run-01_bold.nii.gz'\n",
        "\n",
        "images = [sub1_path,sub2_path]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEo0-lK14f3B"
      },
      "source": [
        "# list of NiftiImage objects\n",
        "X = []\n",
        "\n",
        "for index, image_path in enumerate(images):\n",
        "    # load image and remove nan and inf values.\n",
        "    # applying smooth_img to an image with fwhm=None simply cleans up\n",
        "    # non-finite values but otherwise doesn't modify the image.\n",
        "    image = smooth_img(image_path, fwhm=None)\n",
        "    X.append(image)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_7edZWdsdw2",
        "outputId": "3e20f461-13da-4208-a80f-40419dcb889a"
      },
      "source": [
        "print(type(X[0]))\n",
        "print(type(X[0].dataobj))\n",
        "X[0].shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'nibabel.nifti1.Nifti1Image'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 30, 182)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZF0VxX7aHF"
      },
      "source": [
        "Then you can grab the image into a numpy ndarray easily by calling dataobj on each [NiftiImage](https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image) object in the list X. The last dimension is time (the number of 3D slices taken during the course of the task):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AWLKUc05bZL",
        "outputId": "689d4735-a545-483e-ab8f-a11bcba7aea3"
      },
      "source": [
        "numpy_4d_img = X[0].dataobj\n",
        "numpy_4d_img.shape "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 30, 182)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zPEnrp_8C1Y"
      },
      "source": [
        "You can work directly with the NIftiImage object to retrieve slices also (see Nilearn API; it may be less costly in memory to read just the slices we need, rather than loading the entire 4d array). This will be useful when we try to select slices (single 3D images from the time series) that are relevant to the task e.g. the N slices before the participant sees a rewarding cue on the screen is of interest if we want to model fMRI activation leading up to reward (reward anticipation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHV-l6Yl8Dz2",
        "outputId": "2690efe7-c779-4630-cada-49efbb327034"
      },
      "source": [
        "slice_50 = index_img(X[0], 50) # grab slice number 50 into a \n",
        "slice_50_60 = index_img(X[0], slice(50, 60)) # grab slice number 50 to 60 \n",
        "\n",
        "slice_50.shape, slice_50_60.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 64, 30), (64, 64, 30, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}